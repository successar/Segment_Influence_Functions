{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "100%|██████████| 41084/41084 [00:14<00:00, 2864.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad sentences in train; Possible unicode issues if > 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10237/10237 [00:03<00:00, 2624.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad sentences in validation; Possible unicode issues if > 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2076/2076 [00:00<00:00, 2966.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad sentences in test; Possible unicode issues if > 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ner_influence.ebm import load_datamodule\n",
    "from ner_influence.ebm.experiment_utils import dosages \n",
    "data = load_datamodule(transformer=\"google/bigbird-roberta-base\")\n",
    "data._batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3836/3836 [00:08<00:00, 475.43it/s]\n",
      "100%|██████████| 958/958 [00:02<00:00, 478.92it/s]\n",
      "100%|██████████| 191/191 [00:00<00:00, 478.36it/s]\n"
     ]
    }
   ],
   "source": [
    "conll_key = lambda x: x.id.rsplit(\"_\", 1)[0]\n",
    "conll_order = lambda x: int(x.id.rsplit(\"_\", 1)[1])\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    docs = data.combine_to_docs(data[split], key=conll_key, order=conll_order)\n",
    "    data[f\"{split}_docs\"] = data.apply_transform([doc for doc in docs.values()] , transform=lambda x:x, retokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"outputs/ebm_docs/simple_trainer/crf:False;seed:2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2292aba7d44148a952235a9ab83423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INT</th>\n",
       "      <th>O</th>\n",
       "      <th>OUT</th>\n",
       "      <th>POP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.672285</td>\n",
       "      <td>0.878471</td>\n",
       "      <td>0.698488</td>\n",
       "      <td>0.855947</td>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.776298</td>\n",
       "      <td>0.835624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.693050</td>\n",
       "      <td>0.892835</td>\n",
       "      <td>0.722203</td>\n",
       "      <td>0.724814</td>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.758225</td>\n",
       "      <td>0.834718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.682509</td>\n",
       "      <td>0.885595</td>\n",
       "      <td>0.710147</td>\n",
       "      <td>0.784941</td>\n",
       "      <td>0.834718</td>\n",
       "      <td>0.765798</td>\n",
       "      <td>0.834459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>23538.000000</td>\n",
       "      <td>175767.000000</td>\n",
       "      <td>31397.000000</td>\n",
       "      <td>30463.000000</td>\n",
       "      <td>0.834718</td>\n",
       "      <td>261165.000000</td>\n",
       "      <td>261165.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    INT              O           OUT           POP  accuracy  \\\n",
       "precision      0.672285       0.878471      0.698488      0.855947  0.834718   \n",
       "recall         0.693050       0.892835      0.722203      0.724814  0.834718   \n",
       "f1-score       0.682509       0.885595      0.710147      0.784941  0.834718   \n",
       "support    23538.000000  175767.000000  31397.000000  30463.000000  0.834718   \n",
       "\n",
       "               macro avg   weighted avg  \n",
       "precision       0.776298       0.835624  \n",
       "recall          0.758225       0.834718  \n",
       "f1-score        0.765798       0.834459  \n",
       "support    261165.000000  261165.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ner_influence.modelling.trainer import evaluate_ner_model\n",
    "evaluate_ner_model(data, model_path, \"validation_docs\", metrics=\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from ner_influence.modelling.scaffolding import NERTransformerScaffolding\n",
    "\n",
    "scaffolding = NERTransformerScaffolding(\n",
    "    data,\n",
    "    model_path,\n",
    "    save_outputs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.471876"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in scaffolding.model.parameters() if p.requires_grad) / (1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = list(scaffolding.generate_outputs(\"test_docs\", with_feature_vectors=True))\n",
    "train_outputs = list(scaffolding.generate_outputs(\"train_docs\", with_feature_vectors=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "w = 10\n",
    "\n",
    "info = {}\n",
    "int_index = data._label_list.index(\"INT\")\n",
    "for ex in train_outputs:\n",
    "    token = ex[\"tokens\"]\n",
    "    gold_labels = [1 if x == int_index else 0 for x in ex[\"gold_labels\"]]\n",
    "    pred_labels = [1 if x == int_index else 0 for x in ex[\"predicted_labels\"]]\n",
    "    for start, end in dosages(ex[\"tokens\"]):\n",
    "        if any(gold_labels[i] == 1 for i in range(max(0, start - w), min(len(gold_labels), end +  w))):\n",
    "            is_gold_int = sum(gold_labels[start:end]) > 0\n",
    "            is_pred_int = sum(pred_labels[start:end]) > 0\n",
    "            info[(is_gold_int, is_pred_int)] = info.get((is_gold_int, is_pred_int), 0) + 1\n",
    "            # print(is_gold_int, is_pred_int, \" \".join(token[start:end]))\n",
    "\n",
    "print(info)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_dosage_mispredictions(w=10):\n",
    "    for ex in test_outputs:\n",
    "        tokens = ex[\"tokens\"]\n",
    "        gold_labels = [1 if x == int_index else 0 for x in ex[\"gold_labels\"]]\n",
    "        pred_labels = [1 if x == int_index else 0 for x in ex[\"predicted_labels\"]]\n",
    "        for start, end in dosages(tokens):\n",
    "            w_start, w_end = max(0, start - w), min(len(tokens), end + w)\n",
    "            if sum(gold_labels[w_start:w_end]) > 0: # there is true intervention nearby so this is likely to be dosage\n",
    "                is_gold_int = sum(gold_labels[start:end]) > 0\n",
    "                is_pred_int = sum(pred_labels[start:end]) > 0\n",
    "                if is_gold_int == False and is_pred_int == True:\n",
    "                    yield ex, start , end\n",
    "\n",
    "N = len(list(first_dosage_mispredictions()))\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dose(sent, w=10) -> list[bool]:\n",
    "    ints = []\n",
    "    ints_idx = []\n",
    "    tokens = sent.tokens\n",
    "    gold_labels = [1 if x == \"INT\" else 0 for x in sent.labels]\n",
    "    for start, end in dosages(tokens):\n",
    "        w_start, w_end = max(0, start - w), min(len(tokens), end + w)\n",
    "        if sum(gold_labels[w_start:w_end]) > 0:\n",
    "            ints.append(sum(gold_labels[start:end]) > 0)\n",
    "            ints_idx.append((start, end))\n",
    "            \n",
    "    return ints, ints_idx\n",
    "\n",
    "train_dict = {x.id: x for x in data[\"train_docs\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_influence.instance_influence_indexing import InstanceIndexer\n",
    "indexer = InstanceIndexer(scaffolding, normalize=True)\n",
    "indexer.create_index(\"train_docs\")\n",
    "indexer.generate_influence_vectors(\"test_docs\", label_set=\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "neighbors = indexer.batched_search((s[\"id\"] for s, _, _ in first_dosage_mispredictions()), k=3, batch_size=50)\n",
    "\n",
    "has_supp_dose, has_opp_dose = 0, 0\n",
    "shows_inconsistency = 0\n",
    "for sent in tqdm(first_dosage_mispredictions()):\n",
    "    supps, opps = next(neighbors)\n",
    "    top_supp, top_opp = supps[0][0], opps[0][0]\n",
    "    top_supp, top_opp = train_dict[top_supp], train_dict[top_opp]\n",
    "    supp_tokens, supp_tokens_idx = has_dose(top_supp)\n",
    "    opp_tokens, opp_tokens_idx = has_dose(top_opp)\n",
    "\n",
    "    if 0 in supp_tokens:\n",
    "        has_supp_dose += 1\n",
    "    if 1 in opp_tokens:\n",
    "        has_opp_dose += 1\n",
    "    if 0 in supp_tokens and 1 in opp_tokens:\n",
    "        shows_inconsistency += 1\n",
    "\n",
    "print(has_supp_dose, has_opp_dose, shows_inconsistency)\n",
    "print(has_supp_dose / N, has_opp_dose / N, shows_inconsistency / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_influence.np_entity_influence_indexing import NumpyEntityIndexer\n",
    "indexer = NumpyEntityIndexer(scaffolding, normalize=True)\n",
    "indexer.create_index(\"train_docs\")\n",
    "indexer.generate_influence_vectors(\"test_docs\", label_set=\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = indexer.batched_search(((s[\"id\"], end - 1) for s, _, end in first_dosage_mispredictions()), k=3, batch_size=50)\n",
    "\n",
    "has_supp_dose, has_opp_dose = 0, 0\n",
    "shows_inconsistency = 0\n",
    "\n",
    "top_token_has_supp = 0\n",
    "top_token_has_opp = 0\n",
    "token_shows_inconsistency = 0\n",
    "\n",
    "for sent, start, end in tqdm(first_dosage_mispredictions()):\n",
    "    supps, opps = next(neighbors)\n",
    "    top_supp, top_opp = supps[0][0], opps[0][0]\n",
    "    top_supp_token, top_opp_token = supps[0][1], opps[0][1]\n",
    "\n",
    "    top_supp_sent, top_opp_sent = train_dict[top_supp], train_dict[top_opp]\n",
    "    \n",
    "    supp_tokens, supp_tokens_idx = has_dose(top_supp_sent)\n",
    "    opp_tokens, opp_tokens_idx = has_dose(top_opp_sent)\n",
    "\n",
    "    top_supp_token_idx = [i for i, (s, e) in enumerate(supp_tokens_idx) if s <= top_supp_token and e > top_supp_token]\n",
    "    top_opp_token_idx = [i for i, (s, e) in enumerate(opp_tokens_idx) if s <= top_opp_token and e > top_opp_token]\n",
    "\n",
    "    # if len(top_supp_token_idx) == 0 or len(top_opp_token_idx) == 0:\n",
    "    #     print(sent[\"tokens\"], \n",
    "    #         top_supp_sent.tokens[top_supp_token],  len(top_supp_token_idx),\n",
    "    #         top_opp_sent.tokens[top_opp_token], len(top_opp_token_idx))\n",
    "\n",
    "    instance_supp_condition = 0 in supp_tokens\n",
    "    instance_opp_condition = 1 in opp_tokens\n",
    "    token_supp_condition = len(top_supp_token_idx) == 1 and supp_tokens[top_supp_token_idx[0]] == 0\n",
    "    token_opp_condition = len(top_opp_token_idx) == 1 and opp_tokens[top_opp_token_idx[0]] == 1\n",
    "\n",
    "    if token_supp_condition:\n",
    "        top_token_has_supp += 1\n",
    "\n",
    "    if token_opp_condition:\n",
    "        top_token_has_opp += 1\n",
    "\n",
    "    if instance_supp_condition:\n",
    "        has_supp_dose += 1\n",
    "        \n",
    "    if instance_opp_condition:\n",
    "        has_opp_dose += 1\n",
    "        \n",
    "    if instance_supp_condition and instance_opp_condition:\n",
    "        shows_inconsistency += 1\n",
    "\n",
    "    if token_supp_condition and token_opp_condition:\n",
    "        token_shows_inconsistency += 1\n",
    "\n",
    "print(has_supp_dose, has_opp_dose, shows_inconsistency, top_token_has_supp, top_token_has_opp, token_shows_inconsistency)\n",
    "print(has_supp_dose / N, has_opp_dose / N, shows_inconsistency / N, top_token_has_supp / N, top_token_has_opp / N, token_shows_inconsistency / N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_influence.nearest_neighbor_indexing import NNIndexer\n",
    "indexer = NNIndexer(scaffolding, normalize=True)\n",
    "indexer.create_index(\"train_docs\")\n",
    "indexer.generate_influence_vectors(\"test_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = indexer.batched_search(((s[\"id\"], end - 1) for s, _, end in first_dosage_mispredictions()), k=3, batch_size=50)\n",
    "\n",
    "has_supp_dose, has_opp_dose = 0, 0\n",
    "shows_inconsistency = 0\n",
    "\n",
    "top_token_has_supp = 0\n",
    "top_token_has_opp = 0\n",
    "token_shows_inconsistency = 0\n",
    "\n",
    "for sent, start, end in tqdm(first_dosage_mispredictions()):\n",
    "    all_n = next(neighbors)\n",
    "    top_n = [x[0] for x in all_n]\n",
    "\n",
    "    top_supp = top_n[0][0]\n",
    "    top_opp = max(top_n[1:], key=lambda x: x[2])[0]\n",
    "    \n",
    "    top_supp_token, top_opp_token = top_n[0][1], max(top_n[1:], key=lambda x: x[2])[1]\n",
    "\n",
    "    top_supp_sent, top_opp_sent = train_dict[top_supp], train_dict[top_opp]\n",
    "    \n",
    "    supp_tokens, supp_tokens_idx = has_dose(top_supp_sent)\n",
    "    opp_tokens, opp_tokens_idx = has_dose(top_opp_sent)\n",
    "\n",
    "    top_supp_token_idx = [i for i, (s, e) in enumerate(supp_tokens_idx) if s <= top_supp_token and e > top_supp_token]\n",
    "    top_opp_token_idx = [i for i, (s, e) in enumerate(opp_tokens_idx) if s <= top_opp_token and e > top_opp_token]\n",
    "\n",
    "    # if len(top_supp_token_idx) == 0 or len(top_opp_token_idx) == 0:\n",
    "    #     print(sent[\"tokens\"][start:end], \n",
    "    #         top_supp_sent.tokens[top_supp_token],  len(top_supp_token_idx),\n",
    "    #         top_opp_sent.tokens[top_opp_token], len(top_opp_token_idx))\n",
    "\n",
    "    instance_supp_condition = 0 in supp_tokens\n",
    "    instance_opp_condition = 1 in opp_tokens\n",
    "    token_supp_condition = len(top_supp_token_idx) == 1 and supp_tokens[top_supp_token_idx[0]] == 0\n",
    "    token_opp_condition = len(top_opp_token_idx) == 1 and opp_tokens[top_opp_token_idx[0]] == 1\n",
    "\n",
    "    if token_supp_condition:\n",
    "        top_token_has_supp += 1\n",
    "\n",
    "    if token_opp_condition:\n",
    "        top_token_has_opp += 1\n",
    "\n",
    "    if instance_supp_condition:\n",
    "        has_supp_dose += 1\n",
    "        \n",
    "    if instance_opp_condition:\n",
    "        has_opp_dose += 1\n",
    "        \n",
    "    if instance_supp_condition and instance_opp_condition:\n",
    "        shows_inconsistency += 1\n",
    "\n",
    "    if token_supp_condition and token_opp_condition:\n",
    "        token_shows_inconsistency += 1\n",
    "\n",
    "print(has_supp_dose, has_opp_dose, shows_inconsistency, top_token_has_supp, top_token_has_opp, token_shows_inconsistency)\n",
    "print(has_supp_dose / N, has_opp_dose / N, shows_inconsistency / N, top_token_has_supp / N, top_token_has_opp / N, token_shows_inconsistency / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec60fe6eda9024476a390055a4f9290908315f18e2fea088e69d38770a436d29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ner_influence')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
