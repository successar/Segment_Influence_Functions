{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = [line.split(\"\\t\")[1] for line in open(\"neckar/Entities.tsv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = set(qids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# n = 0\n",
    "# pat = '{\"type\":\"item\",\"id\":\"'\n",
    "# lpat = len(pat)\n",
    "# t1 = time.time()\n",
    "\n",
    "# with (gzip.open('neckar/latest-all.json.gz', 'rt') as gf, open(\"entities.jsonl\") as g):\n",
    "#     for i, ln in enumerate(gf):\n",
    "#         if ln.startswith(pat) :\n",
    "#             n += 1\n",
    "#             subln = ln[lpat:].find('\"')\n",
    "#             qid = ln[lpat:lpat + subln]\n",
    "#             if qid in qids:\n",
    "#                 g.write(ln)\n",
    "#         if i % 1000000 == 0:\n",
    "#             print(f\"done {i} in {time.time() - t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8740872it [21:46, 6691.29it/s] \n"
     ]
    }
   ],
   "source": [
    "# from dateutil import parser\n",
    "# import json \n",
    "# from tqdm import tqdm\n",
    "\n",
    "# with open(\"neckar/entities.dates.tsv\", \"w\") as f:\n",
    "#     for line in tqdm(open(\"entities.jsonl\")):\n",
    "#         d = json.loads(line[:-2])\n",
    "#         if \"P571\" in d[\"claims\"]:\n",
    "#             try:\n",
    "#                 time = d[\"claims\"][\"P571\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"]\n",
    "#                 if time.startswith(\"+\") or time.startswith(\"-\"):\n",
    "#                     time = time[1:]\n",
    "#                 year = parser.parse(time).year\n",
    "#                 f.write(f\"{d['id']}\\t{year}\\n\")\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "#         if \"P569\" in d[\"claims\"]:\n",
    "#             try :\n",
    "#                 time = d[\"claims\"][\"P569\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"time\"]\n",
    "#                 if time.startswith(\"+\") or time.startswith(\"-\"):\n",
    "#                     time = time[1:]\n",
    "#                 year = parser.parse(time).year\n",
    "#                 f.write(f\"{d['id']}\\t{year}\\n\")\n",
    "#             except:\n",
    "#                 continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "# from tqdm import tqdm\n",
    "# n = 0\n",
    "# with open(\"neckar/aliases.tsv\", \"w\") as f:\n",
    "#     for line in tqdm(open(\"entities.jsonl\")) :\n",
    "#         n += 1\n",
    "#         data = json.loads(line[:-2])\n",
    "#         qid = data[\"id\"]\n",
    "#         label = data[\"labels\"].get(\"en\", )\n",
    "#         aliases = data[\"aliases\"].get(\"en\", []) + data[\"aliases\"].get(\"en-gb\", [])\n",
    "#         if len(aliases) > 0:\n",
    "#             aliases = list(set([x[\"value\"] for x in aliases]))\n",
    "#             aliases = \"||\".join(aliases)\n",
    "#             f.write(f\"{qid}|||{aliases}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "aliases = {}\n",
    "for line in open(\"neckar/aliases.tsv\"):\n",
    "    qid, alias = line.split(\"|||\", 1)\n",
    "    if \"|||\" in alias:\n",
    "        continue\n",
    "    aliases[qid] = alias.replace(\"\\t\", \" \").strip()\n",
    "\n",
    "with open(\"neckar/wikidata.entities\", \"w\") as f:\n",
    "    for line in tqdm(open(\"neckar/Entities.tsv\")):\n",
    "        t, qid, name = line.strip().split(\"\\t\")\n",
    "        alias = aliases.get(qid, \"\")\n",
    "        f.write(f\"{t}\\t{qid}\\t{name}\\t{alias}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec60fe6eda9024476a390055a4f9290908315f18e2fea088e69d38770a436d29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ner_influence': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
